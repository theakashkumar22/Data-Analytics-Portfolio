{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superstore Dataset - Comprehensive Exploratory Data Analysis\n",
    "\n",
    "**Author:** [Your Name]  \n",
    "**Date:** June 2025  \n",
    "**Objective:** Comprehensive EDA of Superstore sales data to uncover business insights and patterns\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Initial Exploration](#1-data-loading-and-initial-exploration)\n",
    "2. [Data Cleaning and Preprocessing](#2-data-cleaning-and-preprocessing)\n",
    "3. [Univariate Analysis](#3-univariate-analysis)\n",
    "4. [Bivariate and Multivariate Analysis](#4-bivariate-and-multivariate-analysis)\n",
    "5. [Time Series Analysis](#5-time-series-analysis)\n",
    "6. [Geographic Analysis](#6-geographic-analysis)\n",
    "7. [Customer Segmentation Analysis](#7-customer-segmentation-analysis)\n",
    "8. [Product Performance Analysis](#8-product-performance-analysis)\n",
    "9. [Key Business Insights](#9-key-business-insights)\n",
    "10. [Recommendations](#10-recommendations)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import missingno as msno\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"üìä Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('superstore_data.csv')\n",
    "\n",
    "print(\"üîç Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data exploration\n",
    "print(\"üìã DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nüìä FIRST 5 ROWS:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and basic info\n",
    "print(\"üîç DATA TYPES AND INFO:\")\n",
    "print(\"=\" * 30)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nüìà STATISTICAL SUMMARY:\")\n",
    "print(\"=\" * 30)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç MISSING VALUES ANALYSIS:\")\n",
    "print(\"=\" * 30)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "display(missing_df)\n",
    "\n",
    "# Visualize missing data\n",
    "if not missing_df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    msno.bar(df)\n",
    "    plt.title('Missing Data Overview')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"üîç DUPLICATE VALUES ANALYSIS:\")\n",
    "print(\"=\" * 30)\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Total duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"Removing duplicates...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úÖ Removed {duplicates} duplicate rows\")\n",
    "    print(f\"New dataset shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"‚úÖ No duplicate rows found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type conversions\n",
    "print(\"üîß DATA TYPE CONVERSIONS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Convert date columns\n",
    "date_columns = ['Order Date', 'Ship Date']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], format='%d/%m/%Y')\n",
    "        print(f\"‚úÖ Converted {col} to datetime\")\n",
    "\n",
    "# Create additional date features\n",
    "if 'Order Date' in df.columns:\n",
    "    df['Order Year'] = df['Order Date'].dt.year\n",
    "    df['Order Month'] = df['Order Date'].dt.month\n",
    "    df['Order Quarter'] = df['Order Date'].dt.quarter\n",
    "    df['Order Day of Week'] = df['Order Date'].dt.day_name()\n",
    "    df['Order Week'] = df['Order Date'].dt.isocalendar().week\n",
    "\n",
    "# Calculate delivery time\n",
    "if 'Order Date' in df.columns and 'Ship Date' in df.columns:\n",
    "    df['Delivery Days'] = (df['Ship Date'] - df['Order Date']).dt.days\n",
    "\n",
    "print(\"‚úÖ Date features created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "print(\"üîç DATA QUALITY CHECKS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check for negative sales/profit\n",
    "if 'Sales' in df.columns:\n",
    "    negative_sales = (df['Sales'] < 0).sum()\n",
    "    print(f\"Negative sales records: {negative_sales}\")\n",
    "\n",
    "# Check date consistency\n",
    "if 'Order Date' in df.columns and 'Ship Date' in df.columns:\n",
    "    inconsistent_dates = (df['Ship Date'] < df['Order Date']).sum()\n",
    "    print(f\"Inconsistent dates (Ship before Order): {inconsistent_dates}\")\n",
    "\n",
    "# Check for outliers in Sales\n",
    "if 'Sales' in df.columns:\n",
    "    Q1 = df['Sales'].quantile(0.25)\n",
    "    Q3 = df['Sales'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((df['Sales'] < (Q1 - 1.5 * IQR)) | (df['Sales'] > (Q3 + 1.5 * IQR))).sum()\n",
    "    print(f\"Sales outliers (IQR method): {outliers}\")\n",
    "\n",
    "print(\"\\nüìä CLEANED DATASET INFO:\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Order Date'].min()} to {df['Order Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables analysis\n",
    "print(\"üìä CATEGORICAL VARIABLES ANALYSIS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "categorical_cols = ['Category', 'Sub-Category', 'Segment', 'Region', 'Ship Mode']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    if col in df.columns:\n",
    "        value_counts = df[col].value_counts()\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Unique values: {df[col].nunique()}\")\n",
    "        print(f\"  Top 3: {value_counts.head(3).to_dict()}\")\n",
    "        \n",
    "        # Plot\n",
    "        value_counts.plot(kind='bar', ax=axes[i], color='skyblue')\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables analysis\n",
    "print(\"üìä NUMERICAL VARIABLES ANALYSIS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "numerical_cols = ['Sales', 'Delivery Days']\n",
    "if 'Quantity' in df.columns:\n",
    "    numerical_cols.append('Quantity')\n",
    "if 'Discount' in df.columns:\n",
    "    numerical_cols.append('Discount')\n",
    "if 'Profit' in df.columns:\n",
    "    numerical_cols.append('Profit')\n",
    "\n",
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "display(df[numerical_cols].describe())\n",
    "\n",
    "# Distribution plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_cols[:6]):\n",
    "    if col in df.columns:\n",
    "        # Histogram\n",
    "        df[col].hist(bins=30, ax=axes[i], alpha=0.7, color='lightcoral')\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        \n",
    "        # Add statistics text\n",
    "        mean_val = df[col].mean()\n",
    "        median_val = df[col].median()\n",
    "        axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "        axes[i].axvline(median_val, color='blue', linestyle='--', label=f'Median: {median_val:.2f}')\n",
    "        axes[i].legend()\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(len(numerical_cols), 6):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "print(\"üì¶ OUTLIER ANALYSIS:\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(numerical_cols), figsize=(20, 6))\n",
    "if len(numerical_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if col in df.columns:\n",
    "        df.boxplot(column=col, ax=axes[i])\n",
    "        axes[i].set_title(f'{col} Box Plot')\n",
    "        \n",
    "        # Calculate and display outlier statistics\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "        print(f\"  Range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bivariate and Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"üîó CORRELATION ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "corr_cols = [col for col in numerical_cols if col in df.columns]\n",
    "if len(corr_cols) > 1:\n",
    "    correlation_matrix = df[corr_cols].corr()\n",
    "    \n",
    "    # Display correlation matrix\n",
    "    print(\"Correlation Matrix:\")\n",
    "    display(correlation_matrix)\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    # Strong correlations\n",
    "    print(\"\\nStrong Correlations (|r| > 0.5):\")\n",
    "    strong_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_val = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.5:\n",
    "                strong_corr.append((correlation_matrix.columns[i], \n",
    "                                 correlation_matrix.columns[j], \n",
    "                                 corr_val))\n",
    "    \n",
    "    for col1, col2, corr in strong_corr:\n",
    "        print(f\"  {col1} vs {col2}: {corr:.3f}\")\nelse:\n",
    "    print(\"Not enough numerical variables for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales analysis by different dimensions\n",
    "print(\"üí∞ SALES ANALYSIS BY DIMENSIONS:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Sales by Category\n",
    "if 'Category' in df.columns and 'Sales' in df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Sales by Category\n",
    "    category_sales = df.groupby('Category')['Sales'].agg(['sum', 'mean', 'count']).reset_index()\n",
    "    category_sales.plot(x='Category', y='sum', kind='bar', ax=axes[0,0], color='lightblue')\n",
    "    axes[0,0].set_title('Total Sales by Category')\n",
    "    axes[0,0].set_ylabel('Total Sales ($)')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Sales by Region\n",
    "    if 'Region' in df.columns:\n",
    "        region_sales = df.groupby('Region')['Sales'].sum().reset_index()\n",
    "        region_sales.plot(x='Region', y='Sales', kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "        axes[0,1].set_title('Total Sales by Region')\n",
    "        axes[0,1].set_ylabel('Total Sales ($)')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Sales by Segment\n",
    "    if 'Segment' in df.columns:\n",
    "        segment_sales = df.groupby('Segment')['Sales'].sum().reset_index()\n",
    "        segment_sales.plot(x='Segment', y='Sales', kind='bar', ax=axes[1,0], color='salmon')\n",
    "        axes[1,0].set_title('Total Sales by Segment')\n",
    "        axes[1,0].set_ylabel('Total Sales ($)')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Sales by Ship Mode\n",
    "    if 'Ship Mode' in df.columns:\n",
    "        shipmode_sales = df.groupby('Ship Mode')['Sales'].sum().reset_index()\n",
    "        shipmode_sales.plot(x='Ship Mode', y='Sales', kind='bar', ax=axes[1,1], color='gold')\n",
    "        axes[1,1].set_title('Total Sales by Ship Mode')\n",
    "        axes[1,1].set_ylabel('Total Sales ($)')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSales Summary by Category:\")\n",
    "    display(category_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation analysis\n",
    "print(\"üìä CROSS-TABULATION ANALYSIS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if 'Category' in df.columns and 'Region' in df.columns:\n",
    "    # Category vs Region crosstab\n",
    "    crosstab_cat_region = pd.crosstab(df['Category'], df['Region'], values=df['Sales'], aggfunc='sum')\n",
    "    \n",
    "    print(\"Sales by Category and Region:\")\n",
    "    display(crosstab_cat_region)\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(crosstab_cat_region, annot=True, fmt='.0f', cmap='YlOrRd')\n",
    "    plt.title('Sales Heatmap: Category vs Region')\n",
    "    plt.show()\n",
    "\n",
    "if 'Segment' in df.columns and 'Category' in df.columns:\n",
    "    # Segment vs Category crosstab\n",
    "    crosstab_seg_cat = pd.crosstab(df['Segment'], df['Category'], values=df['Sales'], aggfunc='sum')\n",
    "    \n",
    "    print(\"\\nSales by Segment and Category:\")\n",
    "    display(crosstab_seg_cat)\n",
    "    \n",
    "    # Stacked bar chart\n",
    "    crosstab_seg_cat.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    plt.title('Sales Distribution: Segment vs Category')\n",
    "    plt.xlabel('Segment')\n",
    "    plt.ylabel('Sales ($)')\n",
    "    plt.legend(title='Category')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "print(\"üìà TIME SERIES ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "if 'Order Date' in df.columns and 'Sales' in df.columns:\n",
    "    # Monthly sales trend\n",
    "    monthly_sales = df.groupby(df['Order Date'].dt.to_period('M'))['Sales'].agg(['sum', 'count']).reset_index()\n",
    "    monthly_sales['Order Date'] = monthly_sales['Order Date'].dt.to_timestamp()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Monthly sales trend\n",
    "    axes[0,0].plot(monthly_sales['Order Date'], monthly_sales['sum'], marker='o', linewidth=2)\n",
    "    axes[0,0].set_title('Monthly Sales Trend')\n",
    "    axes[0,0].set_xlabel('Date')\n",
    "    axes[0,0].set_ylabel('Total Sales ($)')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Monthly order count\n",
    "    axes[0,1].plot(monthly_sales['Order Date'], monthly_sales['count'], marker='s', color='orange', linewidth=2)\n",
    "    axes[0,1].set_title('Monthly Order Count')\n",
    "    axes[0,1].set_xlabel('Date')\n",
    "    axes[0,1].set_ylabel('Number of Orders')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Yearly sales comparison\n",
    "    if 'Order Year' in df.columns:\n",
    "        yearly_sales = df.groupby('Order Year')['Sales'].sum()\n",
    "        yearly_sales.plot(kind='bar', ax=axes[1,0], color='lightblue')\n",
    "        axes[1,0].set_title('Yearly Sales Comparison')\n",
    "        axes[1,0].set_xlabel('Year')\n",
    "        axes[1,0].set_ylabel('Total Sales ($)')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Quarterly sales pattern\n",
    "    if 'Order Quarter' in df.columns:\n",
    "        quarterly_sales = df.groupby('Order Quarter')['Sales'].sum()\n",
    "        quarterly_sales.plot(kind='bar', ax=axes[1,1], color='lightgreen')\n",
    "        axes[1,1].set_title('Quarterly Sales Pattern')\n",
    "        axes[1,1].set_xlabel('Quarter')\n",
    "        axes[1,1].set_ylabel('Total Sales ($)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Seasonal analysis\n",
    "    print(\"\\nSeasonal Analysis - Sales by Quarter:\")\n",
    "    if 'Order Quarter' in df.columns:\n",
    "        quarterly_stats = df.groupby('Order Quarter')['Sales'].agg(['sum', 'mean', 'count'])\n",
    "        display(quarterly_stats)\n",
    "    \n",
    "    # Day of week analysis\n",
    "    if 'Order Day of Week' in df.columns:\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        dow_sales = df.groupby('Order Day of Week')['Sales'].sum().reindex(day_order)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        dow_sales.plot(kind='bar', color='skyblue')\n",
    "        plt.title('Sales by Day of Week')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('Total Sales ($)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Delivery time analysis\n",
    "print(\"üöö DELIVERY TIME ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "if 'Delivery Days' in df.columns:\n",
    "    # Delivery statistics\n",
    "    delivery_stats = df['Delivery Days'].describe()\n",
    "    print(\"Delivery Days Statistics:\")\n",
    "    display(delivery_stats)\n",
    "    \n",
    "    # Delivery time by ship mode\n",
    "    if 'Ship Mode' in df.columns:\n",
    "        delivery_by_mode = df.groupby('Ship Mode')['Delivery Days'].agg(['mean', 'median', 'std'])\n",
    "        print(\"\\nDelivery Time by Ship Mode:\")\n",
    "        display(delivery_by_mode)\n",
    "        \n",
    "        # Box plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        df.boxplot(column='Delivery Days', by='Ship Mode')\n",
    "        plt.title('Delivery Days by Ship Mode')\n",
    "        plt.suptitle('')  # Remove default title\n",
    "        plt.xlabel('Ship Mode')\n",
    "        plt.ylabel('Delivery Days')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic analysis\n",
    "print(\"üó∫Ô∏è GEOGRAPHIC ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Sales by State\n",
    "if 'State' in df.columns and 'Sales' in df.columns:\n",
    "    state_analysis = df.groupby('State').agg({\n",
    "        'Sales': ['sum', 'mean', 'count'],\n",
    "        'Customer ID': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    state_analysis.columns = ['Total Sales', 'Avg Sales', 'Orders', 'Customers']\n",
    "    state_analysis = state_analysis.sort_values('Total Sales', ascending=False)\n",
    "    \n",
    "    print(\"Top 10 States by Sales:\")\n",
    "    display(state_analysis.head(10))\n",
    "    \n",
    "    # Top states visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Top 10 states by sales\n",
    "    state_analysis.head(10)['Total Sales'].plot(kind='barh', ax=axes[0], color='lightcoral')\n",
    "    axes[0].set_title('Top 10 States by Total Sales')\n",
    "    axes[0].set_xlabel('Total Sales ($)')\n",
    "    \n",
    "    # Top 10 states by number of customers\n",
    "    state_analysis.head(10)['Customers'].plot(kind='barh', ax=axes[1], color='lightblue')\n",
    "    axes[1].set_title('Top 10 States by Number of Customers')\n",
    "    axes[1].set_xlabel('Number of Customers')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Sales by City\n",
    "if 'City' in df.columns:\n",
    "    city_analysis = df.groupby('City').agg({\n",
    "        'Sales': 'sum',\n",
    "        'Order ID': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    city_analysis.columns = ['Total Sales', 'Orders']\n",
    "    city_analysis = city_analysis.sort_values('Total Sales', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 15 Cities by Sales:\")\n",
    "    display(city_analysis.head(15))\n",
    "    \n",
    "    # Top cities visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    city_analysis.head(15)['Total Sales'].plot(kind='bar', color='gold')\n",
    "    plt.title('Top 15 Cities by Total Sales')\n",
    "    plt.xlabel('City')\n",
    "    plt.ylabel('Total Sales ($)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Regional performance comparison\n",
    "if 'Region' in df.columns:\n",
    "    regional_analysis = df.groupby('Region').agg({\n",
    "        'Sales': ['sum', 'mean'],\n",
    "        'Order ID': 'nunique',\n",
    "        'Customer ID': 'nunique',\n",
    "        'Delivery Days': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    regional_analysis.columns = ['Total Sales', 'Avg Sales', 'Orders', 'Customers', 'Avg Delivery Days']\n",
    "    \n",
    "    print(\"\\nüìä Regional Performance Summary:\")\n",
    "    display(regional_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Customer Segmentation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer analysis\n",
    "print(\"üë• CUSTOMER SEGMENTATION ANALYSIS:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if 'Customer ID' in df.columns and 'Sales' in df.columns:\n",
    "    # Customer-level analysis\n",
    "    customer_analysis = df.groupby('Customer ID').agg({\n",
    "        'Sales': ['sum', 'mean', 'count'],\n",
    "        'Order Date': ['min', 'max'],\n",
    "        'Category': lambda x: x.nunique()\n",
    "    }).round(2)\n",
    "    \n",
    "    customer_analysis.columns = ['Total Sales', 'Avg Order Value', 'Order Frequency', \n",
    "                                'First Order', 'Last Order', 'Categories Purchased']\n",
    "    \n",
    "    # Calculate customer lifetime (days)\n",
    "    customer_analysis['Customer Lifetime (Days)'] = (\n",
    "        customer_analysis['Last Order'] - customer_analysis['First Order']\n",
    "    ).dt.days\n",
    "    \n",
    "    # Customer segmentation based on RFM-like analysis\n",
    "    # Recency: Days since last order\n",
    "    max_date = df['Order Date'].max()\n",
    "    customer_recency = df.groupby('Customer ID')['Order Date'].max().reset_index()\n",
    "    customer_recency['Recency'] = (max_date - customer_recency['Order Date']).dt.days\n",
    "    \n",
    "    # Merge with customer analysis\n",
    "    customer_analysis = customer_analysis.reset_index().merge(\n",
    "        customer_recency[['Customer ID', 'Recency']], on='Customer ID'\n",
    "    )\n",
    "    \n",
    "    # Define customer segments\n",
    "    def categorize_customers(row):\n",
    "        if row['Total Sales'] >= customer_analysis['Total Sales'].quantile(0.8):\n",
    "            return 'High Value'\n",
    "        elif row['Order Frequency'] >= customer_analysis['Order Frequency'].quantile(0.8):\n",
    "            return 'Frequent'\n",
    "        elif row['Recency'] <= customer_analysis['Recency'].quantile(0.2):\n",
    "            return 'Recent'\n",
    "        else:\n",
    "            return 'Regular'\n",
    "    \n",
    "    customer_analysis['Segment'] = customer_analysis.apply(categorize_customers, axis=1)\n",
    "    \n",
    "    print(\"Customer Segments Distribution:\")\n",
    "    segment_dist = customer_analysis['Segment'].value_counts()\n",
    "    display(segment_dist)\n",
    "    \n",
    "    # Visualize customer segments\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Segment distribution\n",
    "    segment_dist.plot(kind='pie', ax=axes[0,0], autopct='%1.1f%%')\n",
    "    axes[0,0].set_title('Customer Segment Distribution')\n",
    "    axes[0,0].set_ylabel('')\n",
    "    \n",
    "    # Average sales by segment\n",
    "    segment_sales = customer_analysis.groupby('Segment')['Total Sales'].mean()\n",
    "    segment_sales.plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "    axes[0,1].set_title('Average Sales by Customer Segment')\n",
    "    axes[0,1].set_ylabel('Average Sales ($)')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Order frequency by segment\n",
    "    segment_freq = customer_analysis.groupby('Segment')['Order Frequency'].mean()\n",
    "    segment_freq.plot(kind='bar', ax=axes[1,0], color='orange')\n",
    "    axes[1,0].set_title('Average Order Frequency by Segment')\n",
    "    axes[1,0].set_ylabel('Orders per Customer')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Customer lifetime by segment\n",
    "    segment_lifetime = customer_analysis.groupby('Segment')['Customer Lifetime (Days)'].mean()\n",
    "    segment_lifetime.plot(kind='bar', ax=axes[1,1], color='salmon')\n",
    "    axes[1,1].set_title('Average Customer Lifetime by Segment')\n",
    "    axes[1,1].set_ylabel('Days')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Top customers\n",
    "    print(\"\\nüèÜ Top 10 Customers by Total Sales:\")\n",
    "    top_customers = customer_analysis.nlargest(10, 'Total Sales')[[\n",
    "        'Customer ID', 'Total Sales', 'Order Frequency', 'Avg Order Value', 'Segment'\n",
    "    ]]\n",
    "    display(top_customers)\n",
    "\n",
    "# Segment-wise performance\n",
    "if 'Segment' in df.columns:\n",
    "    segment_performance = df.groupby('Segment').agg({\n",
    "        'Sales': ['sum', 'mean'],\n",
    "        'Order ID': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    segment_performance.columns = ['Total Sales', 'Avg Sales', 'Orders', 'Customers']\n",
    "    \n",
    "    print(\"\\nüìä Business Segment Performance:\")\n",
    "    display(segment_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Product Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product performance analysis\n",
    "print(\"üõçÔ∏è PRODUCT PERFORMANCE ANALYSIS:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Category performance\n",
    "if 'Category' in df.columns and 'Sales' in df.columns:\n",
    "    category_performance = df.groupby('Category').agg({\n",
    "        'Sales': ['sum', 'mean', 'count'],\n",
    "        'Customer ID': 'nunique',\n",
    "        'Sub-Category': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    category_performance.columns = ['Total Sales', 'Avg Sales', 'Orders', 'Customers', 'Sub-Categories']\n",
    "    category_performance = category_performance.sort_values('Total Sales', ascending=False)\n",
    "    \n",
    "    print(\"üìä Category Performance Summary:\")\n",
    "    display(category_performance)\n",
    "\n",
    "# Sub-category analysis\n",
    "if 'Sub-Category' in df.columns:\n",
    "    subcategory_performance = df.groupby(['Category', 'Sub-Category']).agg({\n",
    "        'Sales': ['sum', 'mean', 'count']\n",
    "    }).round(2)\n",
    "    \n",
    "    subcategory_performance.columns = ['Total Sales', 'Avg Sales', 'Orders']\n",
    "    subcategory_performance = subcategory_performance.sort_values('Total Sales', ascending=False)\n",
    "    \n",
    "    print(\"\\nüèÜ Top 15 Sub-Categories by Sales:\")\n",
    "    display(subcategory_performance.head(15))\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Top sub-categories by sales\n",
    "    top_subcats = subcategory_performance.head(10)\n",
    "    subcats_names = [f\"{idx[0]}\\n{idx[1]}\" for idx in top_subcats.index]\n",
    "    \n",
    "    axes[0,0].bar(range(len(top_subcats)), top_subcats['Total Sales'], color='skyblue')\n",
    "    axes[0,0].set_title('Top 10 Sub-Categories by Total Sales')\n",
    "    axes[0,0].set_xlabel('Sub-Category')\n",
    "    axes[0,0].set_ylabel('Total Sales ($)')\n",
    "    axes[0,0].set_xticks(range(len(top_subcats)))\n",
    "    axes[0,0].set_xticklabels(subcats_names, rotation=45, ha='right')\n",
    "    \n",
    "    # Category market share\n",
    "    category_sales = df.groupby('Category')['Sales'].sum()\n",
    "    axes[0,1].pie(category_sales.values, labels=category_sales.index, autopct='%1.1f%%')\n",
    "    axes[0,1].set_title('Market Share by Category')\n",
    "    \n",
    "    # Orders by category\n",
    "    category_orders = df.groupby('Category').size()\n",
    "    category_orders.plot(kind='bar', ax=axes[1,0], color='lightgreen')\n",
    "    axes[1,0].set_title('Number of Orders by Category')\n",
    "    axes[1,0].set_ylabel('Number of Orders')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Average order value by category\n",
    "    avg_order_value = df.groupby('Category')['Sales'].mean()\n",
    "    avg_order_value.plot(kind='bar', ax=axes[1,1], color='coral')\n",
    "    axes[1,1].set_title('Average Order Value by Category')\n",
    "    axes[1,1].set_ylabel('Average Sales ($)')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Product name analysis (if available)\n",
    "if 'Product Name' in df.columns:\n",
    "    product_performance = df.groupby('Product Name').agg({\n",
    "        'Sales': ['sum', 'count'],\n",
    "        'Customer ID': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    product_performance.columns = ['Total Sales', 'Orders', 'Customers']\n",
    "    product_performance = product_performance.sort_values('Total Sales', ascending=False)\n",
    "    \n",
    "    print(\"\\nüåü Top 10 Products by Sales:\")\n",
    "    display(product_performance.head(10))\n",
    "    \n",
    "    # Most popular products (by order count)\n",
    "    print(\"\\nüìà Top 10 Most Ordered Products:\")\n",
    "    most_ordered = product_performance.sort_values('Orders', ascending=False).head(10)\n",
    "    display(most_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business insights generation\n",
    "print(\"üí° KEY BUSINESS INSIGHTS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Sales insights\n",
    "if 'Sales' in df.columns:\n",
    "    total_sales = df['Sales'].sum()\n",
    "    avg_order_value = df['Sales'].mean()\n",
    "    insights.append(f\"üí∞ Total Revenue: ${total_sales:,.2f}\")\n",
    "    insights.append(f\"üìä Average Order Value: ${avg_order_value:.2f}\")\n",
    "\n",
    "# Customer insights\n",
    "if 'Customer ID' in df.columns:\n",
    "    unique_customers = df['Customer ID'].nunique()\n",
    "    insights.append(f\"üë• Total Unique Customers: {unique_customers:,}\")\n",
    "    \n",
    "    if 'Order ID' in df.columns:\n",
    "        unique_orders = df['Order ID'].nunique()\n",
    "        orders_per_customer = unique_orders / unique_customers\n",
    "        insights.append(f\"üîÑ Orders per Customer: {orders_per_customer:.2f}\")\n",
    "\n",
    "# Category insights\n",
    "if 'Category' in df.columns and 'Sales' in df.columns:\n",
    "    top_category = df.groupby('Category')['Sales'].sum().idxmax()\n",
    "    top_category_sales = df.groupby('Category')['Sales'].sum().max()\n",
    "    insights.append(f\"üèÜ Top Category: {top_category} (${top_category_sales:,.2f})\")\n",
    "\n",
    "# Regional insights\n",
    "if 'Region' in df.columns and 'Sales' in df.columns:\n",
    "    top_region = df.groupby('Region')['Sales'].sum().idxmax()\n",
    "    top_region_sales = df.groupby('Region')['Sales'].sum().max()\n",
    "    insights.append(f\"üåç Top Region: {top_region} (${top_region_sales:,.2f})\")\n",
    "\n",
    "# Segment insights\n",
    "if 'Segment' in df.columns and 'Sales' in df.columns:\n",
    "    top_segment = df.groupby('Segment')['Sales'].sum().idxmax()\n",
    "    top_segment_sales = df.groupby('Segment')['Sales'].sum().max()\n",
    "    insights.append(f\"üéØ Top Segment: {top_segment} (${top_segment_sales:,.2f})\")\n",
    "\n",
    "# Time insights\n",
    "if 'Order Year' in df.columns and 'Sales' in df.columns:\n",
    "    yearly_growth = df.groupby('Order Year')['Sales'].sum().pct_change().dropna()\n",
    "    if not yearly_growth.empty:\n",
    "        avg_growth = yearly_growth.mean() * 100\n",
    "        insights.append(f\"üìà Average YoY Growth: {avg_growth:.1f}%\")\n",
    "\n",
    "# Delivery insights\n",
    "if 'Delivery Days' in df.columns:\n",
    "    avg_delivery = df['Delivery Days'].mean()\n",
    "    insights.append(f\"üöö Average Delivery Time: {avg_delivery:.1f} days\")\n",
    "\n",
    "# Print insights\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i:2d}. {insight}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîç DETAILED ANALYSIS SUMMARY:\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics dashboard\n",
    "def create_performance_summary():\n",
    "    summary = {}\n",
    "    \n",
    "    # Sales performance\n",
    "    if 'Sales' in df.columns:\n",
    "        summary['Sales Performance'] = {\n",
    "            'Total Revenue': f\"${df['Sales'].sum():,.2f}\",\n",
    "            'Average Order Value': f\"${df['Sales'].mean():.2f}\",\n",
    "            'Median Order Value': f\"${df['Sales'].median():.2f}\",\n",
    "            'Sales Standard Deviation': f\"${df['Sales'].std():.2f}\"\n",
    "        }\n",
    "    \n",
    "    # Customer metrics\n",
    "    if 'Customer ID' in df.columns:\n",
    "        summary['Customer Metrics'] = {\n",
    "            'Total Customers': df['Customer ID'].nunique(),\n",
    "            'Total Orders': df['Order ID'].nunique() if 'Order ID' in df.columns else len(df),\n",
    "            'Repeat Customer Rate': f\"{(df.groupby('Customer ID').size() > 1).mean() * 100:.1f}%\"\n",
    "        }\n",
    "    \n",
    "    # Geographic coverage\n",
    "    if 'State' in df.columns:\n",
    "        summary['Geographic Coverage'] = {\n",
    "            'States Covered': df['State'].nunique(),\n",
    "            'Cities Covered': df['City'].nunique() if 'City' in df.columns else 'N/A',\n",
    "            'Regions Covered': df['Region'].nunique() if 'Region' in df.columns else 'N/A'\n",
    "        }\n",
    "    \n",
    "    # Product diversity\n",
    "    if 'Category' in df.columns:\n",
    "        summary['Product Portfolio'] = {\n",
    "            'Categories': df['Category'].nunique(),\n",
    "            'Sub-Categories': df['Sub-Category'].nunique() if 'Sub-Category' in df.columns else 'N/A',\n",
    "            'Unique Products': df['Product Name'].nunique() if 'Product Name' in df.columns else 'N/A'\n",
    "        }\n",
    "    \n",
    "    # Operational metrics\n",
    "    if 'Delivery Days' in df.columns:\n",
    "        summary['Operational Metrics'] = {\n",
    "            'Average Delivery Time': f\"{df['Delivery Days'].mean():.1f} days\",\n",
    "            'Fastest Delivery': f\"{df['Delivery Days'].min()} days\",\n",
    "            'Slowest Delivery': f\"{df['Delivery Days'].max()} days\"\n",
    "        }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "performance_summary = create_performance_summary()\n",
    "\n",
    "for category, metrics in performance_summary.items():\n",
    "    print(f\"\\nüìä {category.upper()}:\")\n",
    "    print(\"-\" * (len(category) + 5))\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  ‚Ä¢ {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business recommendations\n",
    "print(\"üéØ STRATEGIC RECOMMENDATIONS:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Category-based recommendations\n",
    "if 'Category' in df.columns and 'Sales' in df.columns:\n",
    "    category_sales = df.groupby('Category')['Sales'].sum().sort_values(ascending=False)\n",
    "    top_category = category_sales.index[0]\n",
    "    bottom_category = category_sales.index[-1]\n",
    "    \n",
    "    recommendations.append(f\"üöÄ **Focus on {top_category}**: This is your top-performing category. Consider expanding the product line and increasing inventory.\")\n",
    "    recommendations.append(f\"‚ö†Ô∏è  **Improve {bottom_category} Performance**: This category needs attention. Consider marketing campaigns or product improvements.\")\n",
    "\n",
    "# Regional recommendations\n",
    "if 'Region' in df.columns and 'Sales' in df.columns:\n",
    "    region_sales = df.groupby('Region')['Sales'].sum().sort_values(ascending=False)\n",
    "    top_region = region_sales.index[0]\n",
    "    bottom_region = region_sales.index[-1]\n",
    "    \n",
    "    recommendations.append(f\"üåü **Replicate {top_region} Success**: Analyze what works well in {top_region} and apply those strategies to other regions.\")\n",
    "    recommendations.append(f\"üìà **Boost {bottom_region} Sales**: Increase marketing efforts and consider region-specific promotions.\")\n",
    "\n",
    "# Customer segment recommendations\n",
    "if 'Segment' in df.columns and 'Sales' in df.columns:\n",
    "    segment_sales = df.groupby('Segment')['Sales'].sum().sort_values(ascending=False)\n",
    "    top_segment = segment_sales.index[0]\n",
    "    \n",
    "    recommendations.append(f\"üë• **{top_segment} Segment Strategy**: This is your most valuable segment. Develop targeted retention and upselling strategies.\")\n",
    "\n",
    "# Delivery optimization\n",
    "if 'Delivery Days' in df.columns and 'Ship Mode' in df.columns:\n",
    "    delivery_by_mode = df.groupby('Ship Mode')['Delivery Days'].mean().sort_values()\n",
    "    fastest_mode = delivery_by_mode.index[0]\n",
    "    slowest_mode = delivery_by_mode.index[-1]\n",
    "    \n",
    "    recommendations.append(f\"‚ö° **Promote {fastest_mode}**: This shipping method is fastest. Consider incentivizing its use.\")\n",
    "    recommendations.append(f\"üêå **Optimize {slowest_mode}**: This shipping method needs improvement. Work with logistics partners.\")\n",
    "\n",
    "# Seasonal recommendations\n",
    "if 'Order Quarter' in df.columns and 'Sales' in df.columns:\n",
    "    quarterly_sales = df.groupby('Order Quarter')['Sales'].sum()\n",
    "    peak_quarter = quarterly_sales.idxmax()\n",
    "    low_quarter = quarterly_sales.i\n",
    "
